{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5022999e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'task3 (Python 3.9.21)' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'conda install -n task3 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Cell 1: Title & Introduction (Markdown)\n",
    "\"\"\"\n",
    "# Task 3: Dynamic Chatbot with Expanding Knowledge Base\n",
    "\n",
    "This notebook demonstrates how to build a chatbot that dynamically expands its knowledge base using:\n",
    "\n",
    "- **ChromaDB** for vector storage and retrieval,\n",
    "- **Sentence Transformers** for text embeddings,\n",
    "- **Ollama's Mistral model** for generating conversational responses.\n",
    "\n",
    "---\n",
    "\n",
    "The chatbot retrieves relevant knowledge from the vector database to provide context-aware responses.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b4ff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630711bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.PersistentClient(path=\"./data/chromadb/\")\n",
    "\n",
    "# Try to get existing collection or create it if it doesn't exist\n",
    "try:\n",
    "    collection = chroma_client.get_collection(name=\"chatbot_knowledge\")\n",
    "except chromadb.errors.InvalidCollectionException:\n",
    "    collection = chroma_client.create_collection(name=\"chatbot_knowledge\")\n",
    "\n",
    "# Load the embedding model\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "print(\"Database and embedding model ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f4575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_knowledge(text, source):\n",
    "    \"\"\"\n",
    "    Add new knowledge text to the vector database.\n",
    "    :param text: The knowledge text to store.\n",
    "    :param source: A unique ID or source identifier.\n",
    "    \"\"\"\n",
    "    vector = embedding_model.encode(text).tolist()\n",
    "    collection.add(ids=[source], embeddings=[vector], metadatas=[{\"text\": text, \"source\": source}])\n",
    "    print(f\"Added knowledge from source '{source}'.\")\n",
    "\n",
    "def retrieve_knowledge(query, top_k=3):\n",
    "    \"\"\"\n",
    "    Retrieve the most relevant knowledge entries for a query.\n",
    "    :param query: The user query string.\n",
    "    :param top_k: Number of top results to retrieve.\n",
    "    :return: List of knowledge texts.\n",
    "    \"\"\"\n",
    "    query_vector = embedding_model.encode(query).tolist()\n",
    "    results = collection.query(query_embeddings=[query_vector], n_results=top_k)\n",
    "    \n",
    "    if results and results.get(\"documents\") and results[\"documents\"][0]:\n",
    "        return [doc[\"text\"] for doc in results[\"documents\"][0] if doc]\n",
    "    return [\"No relevant knowledge found.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd79f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_knowledge(\n",
    "    \"Artificial Intelligence (AI) is intelligence demonstrated by machines, as opposed to natural intelligence displayed by humans and animals.\",\n",
    "    \"knowledge_1\"\n",
    ")\n",
    "\n",
    "add_knowledge(\n",
    "    \"Machine learning is a subset of AI focused on building systems that learn from data to improve performance on tasks without explicit programming.\",\n",
    "    \"knowledge_2\"\n",
    ")\n",
    "\n",
    "add_knowledge(\n",
    "    \"ChromaDB is an open-source vector database designed to store and query high-dimensional embeddings efficiently.\",\n",
    "    \"knowledge_3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaabeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is AI?\"\n",
    "retrieved_docs = retrieve_knowledge(query)\n",
    "print(f\"Query: {query}\\nRetrieved Knowledge:\")\n",
    "for idx, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"{idx}. {doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e845190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_bot(user_input):\n",
    "    \"\"\"\n",
    "    Generates a chatbot response based on retrieved knowledge and Ollama LLM.\n",
    "    :param user_input: User query string.\n",
    "    :return: Chatbot response string.\n",
    "    \"\"\"\n",
    "    context = \" \".join(retrieve_knowledge(user_input))\n",
    "    prompt = f\"User: {user_input}\\nContext: {context}\\nChatbot:\"\n",
    "    \n",
    "    response = ollama.chat(model=\"mistral\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    return response[\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb422d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = \"Explain artificial intelligence.\"\n",
    "print(f\"User: {test_input}\")\n",
    "print(\"Bot:\", chat_with_bot(test_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6000dbbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "task3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
